{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db5e1130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.python.client import device_lib \n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc72f511",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5bc69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = pd.read_csv('Skype.csv')\n",
    "rawData = rawData[~rawData.isin([np.nan,np.inf,-np.inf]).any(1)] # drop all inf and nan rows\n",
    "# rawTest = pd.read_csv('facebook.csv')\n",
    "# rawTest = rawTest[~rawTest.isin([np.nan,np.inf,-np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c72dfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectCols = rawData.drop(['Flow ID','Src IP','Dst IP','Timestamp','Web_service','Label'],axis=1)\n",
    "X = np.array(selectCols)\n",
    "#X = np.array(rawData.loc[:,['Tot Fwd Pkts','Tot Bwd Pkts','TotLen Fwd Pkts','TotLen Bwd Pkts','Fwd Pkt Len Max','Bwd Pkt Len Max','FirstNPkt_size','Flow Duration','Flow Byts/s','Flow Pkts/s']])\n",
    "Y = rawData.loc[:,['Label']]\n",
    "Y = np.array(pd.get_dummies(Y,columns=['Label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147b9b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19387, 4)\n",
      "(8309, 4)\n",
      "Training set size: (19387, 83)\n",
      "Test set size: (8309, 83)\n"
     ]
    }
   ],
   "source": [
    "Xtrain,XTest,Ytrain,YTest = train_test_split(X,Y,test_size=0.3,random_state=21)\n",
    "\n",
    "#Ytrain = tf.keras.utils.to_categorical(Ytrain, num_classes=3)\n",
    "#YTest = tf.keras.utils.to_categorical(YTest, num_classes=3)\n",
    "print(Ytrain.shape)\n",
    "print(YTest.shape)\n",
    "#Ytrain = Ytrain.reshape(Ytrain.shape[0],)\n",
    "Ytrain = Ytrain.astype(np.float32)\n",
    "\n",
    "#YTest = YTest.reshape(YTest.shape[0],)\n",
    "YTest = YTest.astype(np.float32)\n",
    "print(\"Training set size:\", Xtrain.shape)\n",
    "print(\"Test set size:\",XTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a567efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = list(selectCols.columns)\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111a5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9693ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1c5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = permutation_importance(\n",
    "    forest, Xtrain, Ytrain, n_repeats=10, random_state=21, n_jobs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d641a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "forest_importances.plot.bar(yerr=result.importances_std, ax=ax)\n",
    "ax.set_title(\"Feature importances using permutation on full model\")\n",
    "ax.set_ylabel(\"Mean accuracy decrease\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09ebc6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(selectCols)\n",
    "#X = np.array(selectCols.loc[:,['Idle Max','Idle Mean','Tot Fwd Pkts','Tot Bwd Pkts','TotLen Fwd Pkts','TotLen Bwd Pkts','Fwd Pkt Len Max','Bwd Pkt Len Max','FirstNPkt_size','Flow Duration','Flow Byts/s','Flow Pkts/s','flow_start']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2f58415",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = MinMaxScaler()\n",
    "scalar.fit(X)\n",
    "X = scalar.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fd8ae137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (19387, 83)\n",
      "Test set size: (8309, 83)\n"
     ]
    }
   ],
   "source": [
    "Xtrain,XTest,Ytrain,YTest = train_test_split(X,Y,test_size=0.3,random_state=42)\n",
    "Ytrain = Ytrain.astype(np.float32)\n",
    "YTest = YTest.astype(np.float32)\n",
    "print(\"Training set size:\", Xtrain.shape)\n",
    "print(\"Test set size:\",XTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb6f7320",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_x = X.shape[1]\n",
    "n_y = Y.shape[1]\n",
    "# early stop call back function\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "# save best model during the training process\n",
    "iteration_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    f'models/graph_model_iteration_10.h5',\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(120, input_dim=n_x, activation='relu'))\n",
    "    model.add(Dense(n_y, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a1938ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = KerasClassifier(build_fn=baseline_model,epochs=10, batch_size=10, verbose=1,callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ba4d4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2770/2770 [==============================] - 1s 481us/step - loss: 0.2048 - accuracy: 0.9157\n",
      "Epoch 2/10\n",
      "2770/2770 [==============================] - 1s 472us/step - loss: 0.1349 - accuracy: 0.9380\n",
      "Epoch 3/10\n",
      "2770/2770 [==============================] - 1s 479us/step - loss: 0.1220 - accuracy: 0.94320s - loss:\n",
      "Epoch 4/10\n",
      "2770/2770 [==============================] - 1s 469us/step - loss: 0.1155 - accuracy: 0.9468\n",
      "Epoch 5/10\n",
      "2770/2770 [==============================] - 1s 475us/step - loss: 0.1112 - accuracy: 0.9461\n",
      "Epoch 6/10\n",
      "2770/2770 [==============================] - 1s 478us/step - loss: 0.1087 - accuracy: 0.9466\n",
      "Epoch 7/10\n",
      "2770/2770 [==============================] - 1s 475us/step - loss: 0.1057 - accuracy: 0.9503\n",
      "Epoch 8/10\n",
      "2770/2770 [==============================] - 1s 469us/step - loss: 0.1028 - accuracy: 0.9528\n",
      "Epoch 9/10\n",
      "2770/2770 [==============================] - 1s 463us/step - loss: 0.1026 - accuracy: 0.9515\n",
      "Epoch 10/10\n",
      "2770/2770 [==============================] - 1s 477us/step - loss: 0.1000 - accuracy: 0.9526\n",
      "433/433 [==============================] - 0s 399us/step - loss: 0.1204 - accuracy: 0.9417\n",
      "Test Accuracy: 0.941724419593811\n",
      "Epoch 1/10\n",
      "2770/2770 [==============================] - 1s 461us/step - loss: 0.2193 - accuracy: 0.9113\n",
      "Epoch 2/10\n",
      "2770/2770 [==============================] - 1s 458us/step - loss: 0.1402 - accuracy: 0.9391\n",
      "Epoch 3/10\n",
      "2770/2770 [==============================] - 1s 464us/step - loss: 0.1259 - accuracy: 0.94270s - loss: 0.1271 - accuracy: \n",
      "Epoch 4/10\n",
      "2770/2770 [==============================] - 1s 477us/step - loss: 0.1213 - accuracy: 0.9458\n",
      "Epoch 5/10\n",
      "2770/2770 [==============================] - 1s 462us/step - loss: 0.1153 - accuracy: 0.9482\n",
      "Epoch 6/10\n",
      "2770/2770 [==============================] - 1s 462us/step - loss: 0.1119 - accuracy: 0.9492\n",
      "Epoch 7/10\n",
      "2770/2770 [==============================] - 1s 459us/step - loss: 0.1087 - accuracy: 0.9513\n",
      "Epoch 8/10\n",
      "2770/2770 [==============================] - 1s 462us/step - loss: 0.1063 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "2770/2770 [==============================] - 1s 460us/step - loss: 0.1046 - accuracy: 0.9538\n",
      "Epoch 10/10\n",
      "2770/2770 [==============================] - 1s 459us/step - loss: 0.1014 - accuracy: 0.9549\n",
      "433/433 [==============================] - 0s 407us/step - loss: 0.1053 - accuracy: 0.9500\n",
      "Test Accuracy: 0.9500288963317871\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 2s 467us/step - loss: 0.1948 - accuracy: 0.9210\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 2s 465us/step - loss: 0.1271 - accuracy: 0.9425\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 2s 473us/step - loss: 0.1170 - accuracy: 0.9450\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 2s 487us/step - loss: 0.1102 - accuracy: 0.9495\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 2s 473us/step - loss: 0.1060 - accuracy: 0.9518\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 2s 479us/step - loss: 0.1032 - accuracy: 0.9520\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 2s 475us/step - loss: 0.1017 - accuracy: 0.9516\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 2s 522us/step - loss: 0.0993 - accuracy: 0.9533\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 2s 460us/step - loss: 0.0982 - accuracy: 0.9528\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 2s 454us/step - loss: 0.0962 - accuracy: 0.9560\n",
      "217/217 [==============================] - 0s 396us/step - loss: 0.1151 - accuracy: 0.9479\n",
      "Test Accuracy: 0.9478625059127808\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 2s 459us/step - loss: 0.1925 - accuracy: 0.9203\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 2s 467us/step - loss: 0.1300 - accuracy: 0.9416\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 2s 458us/step - loss: 0.1194 - accuracy: 0.9443\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 2s 451us/step - loss: 0.1139 - accuracy: 0.9487\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 2s 451us/step - loss: 0.1094 - accuracy: 0.9493\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 2s 453us/step - loss: 0.1064 - accuracy: 0.9513\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 2s 463us/step - loss: 0.1044 - accuracy: 0.9516\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 2s 452us/step - loss: 0.1022 - accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 2s 453us/step - loss: 0.1002 - accuracy: 0.9521\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 2s 446us/step - loss: 0.0989 - accuracy: 0.9534\n",
      "217/217 [==============================] - 0s 456us/step - loss: 0.1034 - accuracy: 0.9544\n",
      "Test Accuracy: 0.954361617565155\n",
      "Epoch 1/10\n",
      "   1/4155 [..............................] - ETA: 0s - loss: 1.3476 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "4155/4155 [==============================] - 2s 453us/step - loss: 0.1938 - accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 2s 447us/step - loss: 0.1310 - accuracy: 0.9410\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 2s 452us/step - loss: 0.1190 - accuracy: 0.9443\n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 2s 461us/step - loss: 0.1139 - accuracy: 0.9476\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 2s 453us/step - loss: 0.1088 - accuracy: 0.9488\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 2s 450us/step - loss: 0.1064 - accuracy: 0.9518\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 2s 451us/step - loss: 0.1033 - accuracy: 0.9525\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 2s 453us/step - loss: 0.1013 - accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 2s 466us/step - loss: 0.1006 - accuracy: 0.9534\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 2s 458us/step - loss: 0.0981 - accuracy: 0.9558\n",
      "217/217 [==============================] - 0s 415us/step - loss: 0.1050 - accuracy: 0.9534\n",
      "Test Accuracy: 0.9533506631851196\n",
      "Epoch 1/10\n",
      "4155/4155 [==============================] - 2s 478us/step - loss: 0.1846 - accuracy: 0.9221\n",
      "Epoch 2/10\n",
      "4155/4155 [==============================] - 2s 479us/step - loss: 0.1282 - accuracy: 0.9426\n",
      "Epoch 3/10\n",
      "4155/4155 [==============================] - 2s 482us/step - loss: 0.1176 - accuracy: 0.94710s - loss: 0.1181 - \n",
      "Epoch 4/10\n",
      "4155/4155 [==============================] - 2s 482us/step - loss: 0.1120 - accuracy: 0.94850s -\n",
      "Epoch 5/10\n",
      "4155/4155 [==============================] - 2s 477us/step - loss: 0.1086 - accuracy: 0.9492\n",
      "Epoch 6/10\n",
      "4155/4155 [==============================] - 2s 473us/step - loss: 0.1056 - accuracy: 0.9514\n",
      "Epoch 7/10\n",
      "4155/4155 [==============================] - 2s 482us/step - loss: 0.1039 - accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "4155/4155 [==============================] - 2s 475us/step - loss: 0.1016 - accuracy: 0.9529\n",
      "Epoch 9/10\n",
      "4155/4155 [==============================] - 2s 478us/step - loss: 0.0998 - accuracy: 0.9534\n",
      "Epoch 10/10\n",
      "4155/4155 [==============================] - 2s 477us/step - loss: 0.0976 - accuracy: 0.95630s - loss: 0.0976 - accuracy: 0.95\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.0979 - accuracy: 0.94 - 0s 401us/step - loss: 0.1065 - accuracy: 0.9518\n",
      "Test Accuracy: 0.9517619609832764\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 489us/step - loss: 0.1810 - accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 494us/step - loss: 0.1245 - accuracy: 0.9419\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 490us/step - loss: 0.1154 - accuracy: 0.9463\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 498us/step - loss: 0.1098 - accuracy: 0.9492\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 482us/step - loss: 0.1065 - accuracy: 0.94990s\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 484us/step - loss: 0.1033 - accuracy: 0.9513\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 473us/step - loss: 0.1016 - accuracy: 0.9543\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 451us/step - loss: 0.0994 - accuracy: 0.9535\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 2s 446us/step - loss: 0.0974 - accuracy: 0.9554\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 443us/step - loss: 0.0966 - accuracy: 0.9549\n",
      "  1/109 [..............................] - ETA: 0s - loss: 0.4826 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "109/109 [==============================] - 0s 422us/step - loss: 0.1201 - accuracy: 0.9437\n",
      "Test Accuracy: 0.9436741471290588\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 451us/step - loss: 0.1870 - accuracy: 0.9216\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 445us/step - loss: 0.1262 - accuracy: 0.9431\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 446us/step - loss: 0.1156 - accuracy: 0.9479\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 441us/step - loss: 0.1104 - accuracy: 0.9497\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 447us/step - loss: 0.1065 - accuracy: 0.9493\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 458us/step - loss: 0.1035 - accuracy: 0.9509\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 451us/step - loss: 0.1013 - accuracy: 0.9526\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 456us/step - loss: 0.0986 - accuracy: 0.9544\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 2s 446us/step - loss: 0.0969 - accuracy: 0.9551\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 444us/step - loss: 0.0962 - accuracy: 0.9561\n",
      "109/109 [==============================] - 0s 422us/step - loss: 0.1143 - accuracy: 0.9460\n",
      "Test Accuracy: 0.945984959602356\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 454us/step - loss: 0.1901 - accuracy: 0.9202\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 460us/step - loss: 0.1269 - accuracy: 0.9430\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 451us/step - loss: 0.1175 - accuracy: 0.9457\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 450us/step - loss: 0.1124 - accuracy: 0.9479\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 455us/step - loss: 0.1079 - accuracy: 0.9509\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 453us/step - loss: 0.1048 - accuracy: 0.9516\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 458us/step - loss: 0.1019 - accuracy: 0.9535\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 452us/step - loss: 0.1007 - accuracy: 0.9536\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 2s 462us/step - loss: 0.0991 - accuracy: 0.9542\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 458us/step - loss: 0.0975 - accuracy: 0.9554\n",
      "109/109 [==============================] - 0s 422us/step - loss: 0.1092 - accuracy: 0.9515\n",
      "Test Accuracy: 0.9514731168746948\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 453us/step - loss: 0.1821 - accuracy: 0.9246\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 486us/step - loss: 0.1257 - accuracy: 0.9427\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 485us/step - loss: 0.1149 - accuracy: 0.9480\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 495us/step - loss: 0.1098 - accuracy: 0.95000s - loss:\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 468us/step - loss: 0.1059 - accuracy: 0.9524\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 481us/step - loss: 0.1031 - accuracy: 0.9528\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 460us/step - loss: 0.1019 - accuracy: 0.9545\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 504us/step - loss: 0.0990 - accuracy: 0.9536\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 3s 523us/step - loss: 0.0979 - accuracy: 0.9555\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 478us/step - loss: 0.0959 - accuracy: 0.9565\n",
      "109/109 [==============================] - 0s 404us/step - loss: 0.1087 - accuracy: 0.9509\n",
      "Test Accuracy: 0.9508954286575317\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 467us/step - loss: 0.1811 - accuracy: 0.9253\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 454us/step - loss: 0.1236 - accuracy: 0.9434\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 454us/step - loss: 0.1141 - accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 488us/step - loss: 0.1083 - accuracy: 0.9504\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 470us/step - loss: 0.1057 - accuracy: 0.9515\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 3s 516us/step - loss: 0.1020 - accuracy: 0.95250s - loss: 0.1021 - accuracy: 0.95\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 3s 526us/step - loss: 0.0998 - accuracy: 0.95410s - loss: 0\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 3s 520us/step - loss: 0.0990 - accuracy: 0.9540\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 3s 523us/step - loss: 0.0967 - accuracy: 0.95580s - loss:\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 3s 527us/step - loss: 0.0961 - accuracy: 0.95580s - loss: 0.095\n",
      "109/109 [==============================] - 0s 394us/step - loss: 0.1049 - accuracy: 0.9500\n",
      "Test Accuracy: 0.9500288963317871\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 504us/step - loss: 0.1855 - accuracy: 0.92411s - loss: 0.2\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 479us/step - loss: 0.1258 - accuracy: 0.9425\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 456us/step - loss: 0.1161 - accuracy: 0.9466\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 454us/step - loss: 0.1106 - accuracy: 0.9478\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 448us/step - loss: 0.1074 - accuracy: 0.9502\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 448us/step - loss: 0.1035 - accuracy: 0.9515\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 448us/step - loss: 0.1019 - accuracy: 0.9535\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 448us/step - loss: 0.1005 - accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 2s 452us/step - loss: 0.0978 - accuracy: 0.9547\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 447us/step - loss: 0.0973 - accuracy: 0.9547\n",
      "109/109 [==============================] - 0s 404us/step - loss: 0.1055 - accuracy: 0.9506\n",
      "Test Accuracy: 0.9506065845489502\n",
      "Epoch 1/10\n",
      "   1/4847 [..............................] - ETA: 0s - loss: 1.4140 - accuracy: 0.2000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "4847/4847 [==============================] - 2s 456us/step - loss: 0.1882 - accuracy: 0.9220\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 448us/step - loss: 0.1288 - accuracy: 0.9421\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 445us/step - loss: 0.1180 - accuracy: 0.9454\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 452us/step - loss: 0.1122 - accuracy: 0.9485\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 450us/step - loss: 0.1089 - accuracy: 0.9490\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 454us/step - loss: 0.1053 - accuracy: 0.9516\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 451us/step - loss: 0.1039 - accuracy: 0.9509\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 456us/step - loss: 0.1008 - accuracy: 0.9538\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 2s 453us/step - loss: 0.1007 - accuracy: 0.9514\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 465us/step - loss: 0.0986 - accuracy: 0.9533\n",
      "109/109 [==============================] - 0s 413us/step - loss: 0.0934 - accuracy: 0.9584\n",
      "Test Accuracy: 0.9584055542945862\n",
      "Epoch 1/10\n",
      "4847/4847 [==============================] - 2s 463us/step - loss: 0.1850 - accuracy: 0.9227\n",
      "Epoch 2/10\n",
      "4847/4847 [==============================] - 2s 442us/step - loss: 0.1279 - accuracy: 0.9421\n",
      "Epoch 3/10\n",
      "4847/4847 [==============================] - 2s 449us/step - loss: 0.1179 - accuracy: 0.9457\n",
      "Epoch 4/10\n",
      "4847/4847 [==============================] - 2s 453us/step - loss: 0.1121 - accuracy: 0.9478\n",
      "Epoch 5/10\n",
      "4847/4847 [==============================] - 2s 466us/step - loss: 0.1086 - accuracy: 0.9508\n",
      "Epoch 6/10\n",
      "4847/4847 [==============================] - 2s 459us/step - loss: 0.1059 - accuracy: 0.9507\n",
      "Epoch 7/10\n",
      "4847/4847 [==============================] - 2s 456us/step - loss: 0.1026 - accuracy: 0.9525\n",
      "Epoch 8/10\n",
      "4847/4847 [==============================] - 2s 454us/step - loss: 0.1006 - accuracy: 0.9542\n",
      "Epoch 9/10\n",
      "4847/4847 [==============================] - 2s 459us/step - loss: 0.0998 - accuracy: 0.9540\n",
      "Epoch 10/10\n",
      "4847/4847 [==============================] - 2s 462us/step - loss: 0.0979 - accuracy: 0.9550\n",
      "109/109 [==============================] - 0s 422us/step - loss: 0.1003 - accuracy: 0.9529\n",
      "Test Accuracy: 0.9529173970222473\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 467us/step - loss: 0.1806 - accuracy: 0.9230\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 459us/step - loss: 0.1241 - accuracy: 0.9435\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 459us/step - loss: 0.1144 - accuracy: 0.9472\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.1092 - accuracy: 0.9501\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 455us/step - loss: 0.1063 - accuracy: 0.9506\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 463us/step - loss: 0.1029 - accuracy: 0.9516\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 459us/step - loss: 0.1006 - accuracy: 0.9540\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 464us/step - loss: 0.0989 - accuracy: 0.9539\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 458us/step - loss: 0.0976 - accuracy: 0.9545\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.0957 - accuracy: 0.9568\n",
      "87/87 [==============================] - 0s 414us/step - loss: 0.1099 - accuracy: 0.9480\n",
      "Test Accuracy: 0.9480144381523132\n",
      "Epoch 1/10\n",
      "   1/4986 [..............................] - ETA: 0s - loss: 1.3408 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "4986/4986 [==============================] - 2s 463us/step - loss: 0.1772 - accuracy: 0.9240\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.1229 - accuracy: 0.9446\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 458us/step - loss: 0.1147 - accuracy: 0.9464\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 463us/step - loss: 0.1092 - accuracy: 0.9499\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 466us/step - loss: 0.1057 - accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 459us/step - loss: 0.1029 - accuracy: 0.9516\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.1002 - accuracy: 0.9543\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.0984 - accuracy: 0.9549\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.0969 - accuracy: 0.9558\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.0967 - accuracy: 0.9543\n",
      "87/87 [==============================] - 0s 425us/step - loss: 0.1014 - accuracy: 0.9556\n",
      "Test Accuracy: 0.9555956721305847\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1843 - accuracy: 0.9249\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1259 - accuracy: 0.9430\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1166 - accuracy: 0.9453\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 470us/step - loss: 0.1103 - accuracy: 0.9490\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 478us/step - loss: 0.1071 - accuracy: 0.9507\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 477us/step - loss: 0.1043 - accuracy: 0.95160s -\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 479us/step - loss: 0.1019 - accuracy: 0.9533\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 474us/step - loss: 0.1008 - accuracy: 0.9527\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.0987 - accuracy: 0.9548\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 473us/step - loss: 0.0975 - accuracy: 0.9550\n",
      "87/87 [==============================] - 0s 425us/step - loss: 0.1304 - accuracy: 0.9469\n",
      "Test Accuracy: 0.9469314217567444\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 467us/step - loss: 0.1811 - accuracy: 0.9222\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 460us/step - loss: 0.1246 - accuracy: 0.94361s - loss: - ETA: \n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 468us/step - loss: 0.1141 - accuracy: 0.9476\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 466us/step - loss: 0.1092 - accuracy: 0.9498\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 459us/step - loss: 0.1054 - accuracy: 0.9514\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 470us/step - loss: 0.1035 - accuracy: 0.9513\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 467us/step - loss: 0.1014 - accuracy: 0.9525\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.0994 - accuracy: 0.9533\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.0981 - accuracy: 0.9541\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 470us/step - loss: 0.0966 - accuracy: 0.9540\n",
      "87/87 [==============================] - 0s 425us/step - loss: 0.1071 - accuracy: 0.9509\n",
      "Test Accuracy: 0.95090252161026\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 479us/step - loss: 0.1836 - accuracy: 0.9250\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1244 - accuracy: 0.9431\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1144 - accuracy: 0.9475\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1095 - accuracy: 0.9497\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 480us/step - loss: 0.1053 - accuracy: 0.9513\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.1030 - accuracy: 0.9533\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 472us/step - loss: 0.1005 - accuracy: 0.9535\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.0993 - accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 471us/step - loss: 0.0975 - accuracy: 0.9554\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 464us/step - loss: 0.0966 - accuracy: 0.95620s\n",
      "87/87 [==============================] - 0s 471us/step - loss: 0.1010 - accuracy: 0.9531\n",
      "Test Accuracy: 0.9530686140060425\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 455us/step - loss: 0.1865 - accuracy: 0.9189\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 470us/step - loss: 0.1261 - accuracy: 0.9427\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 458us/step - loss: 0.1166 - accuracy: 0.9439\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 464us/step - loss: 0.1106 - accuracy: 0.9477\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.1071 - accuracy: 0.9497\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.1046 - accuracy: 0.9514\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 469us/step - loss: 0.1022 - accuracy: 0.9519\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.1009 - accuracy: 0.9540\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.0987 - accuracy: 0.9547\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 464us/step - loss: 0.0975 - accuracy: 0.9552\n",
      "87/87 [==============================] - 0s 437us/step - loss: 0.0990 - accuracy: 0.9531\n",
      "Test Accuracy: 0.9530686140060425\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 472us/step - loss: 0.1835 - accuracy: 0.9238\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.1231 - accuracy: 0.9445\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 458us/step - loss: 0.1139 - accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 452us/step - loss: 0.1081 - accuracy: 0.9510\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 455us/step - loss: 0.1054 - accuracy: 0.9499\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.1016 - accuracy: 0.9547\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.1005 - accuracy: 0.9549\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.0984 - accuracy: 0.9550\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 453us/step - loss: 0.0968 - accuracy: 0.9552\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 462us/step - loss: 0.0958 - accuracy: 0.9556\n",
      "87/87 [==============================] - 0s 414us/step - loss: 0.1083 - accuracy: 0.9498\n",
      "Test Accuracy: 0.9498013854026794\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 455us/step - loss: 0.1843 - accuracy: 0.9237\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.1254 - accuracy: 0.9428\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.1153 - accuracy: 0.9450\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.1094 - accuracy: 0.9507\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 463us/step - loss: 0.1065 - accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 458us/step - loss: 0.1038 - accuracy: 0.9521\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 457us/step - loss: 0.1023 - accuracy: 0.9533\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 460us/step - loss: 0.0997 - accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.0982 - accuracy: 0.9547\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.0972 - accuracy: 0.9558\n",
      "87/87 [==============================] - 0s 425us/step - loss: 0.1086 - accuracy: 0.9498\n",
      "Test Accuracy: 0.9498013854026794\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 464us/step - loss: 0.1850 - accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 470us/step - loss: 0.1258 - accuracy: 0.9429\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.1157 - accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 461us/step - loss: 0.1101 - accuracy: 0.9487\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 491us/step - loss: 0.1063 - accuracy: 0.95070s - loss:\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 3s 543us/step - loss: 0.1029 - accuracy: 0.9519\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 3s 531us/step - loss: 0.1016 - accuracy: 0.95280s - loss: 0\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 3s 524us/step - loss: 0.0995 - accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 488us/step - loss: 0.0984 - accuracy: 0.9531\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 464us/step - loss: 0.0969 - accuracy: 0.9561\n",
      "87/87 [==============================] - 0s 402us/step - loss: 0.1030 - accuracy: 0.9549\n",
      "Test Accuracy: 0.954857349395752\n",
      "Epoch 1/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.1863 - accuracy: 0.9227\n",
      "Epoch 2/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.1254 - accuracy: 0.9439\n",
      "Epoch 3/10\n",
      "4986/4986 [==============================] - 2s 455us/step - loss: 0.1166 - accuracy: 0.9467\n",
      "Epoch 4/10\n",
      "4986/4986 [==============================] - 2s 459us/step - loss: 0.1104 - accuracy: 0.9493\n",
      "Epoch 5/10\n",
      "4986/4986 [==============================] - 2s 467us/step - loss: 0.1071 - accuracy: 0.9501\n",
      "Epoch 6/10\n",
      "4986/4986 [==============================] - 2s 456us/step - loss: 0.1045 - accuracy: 0.9513\n",
      "Epoch 7/10\n",
      "4986/4986 [==============================] - 2s 466us/step - loss: 0.1024 - accuracy: 0.9534\n",
      "Epoch 8/10\n",
      "4986/4986 [==============================] - 2s 460us/step - loss: 0.1006 - accuracy: 0.9531\n",
      "Epoch 9/10\n",
      "4986/4986 [==============================] - 2s 463us/step - loss: 0.0988 - accuracy: 0.95380s - loss: 0.1\n",
      "Epoch 10/10\n",
      "4986/4986 [==============================] - 2s 465us/step - loss: 0.0977 - accuracy: 0.9549\n",
      "87/87 [==============================] - 0s 403us/step - loss: 0.0960 - accuracy: 0.9520\n",
      "Test Accuracy: 0.9519681930541992\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 3s 488us/step - loss: 0.1825 - accuracy: 0.9225\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 3s 479us/step - loss: 0.1234 - accuracy: 0.9436\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 3s 478us/step - loss: 0.1142 - accuracy: 0.9458\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 3s 478us/step - loss: 0.1092 - accuracy: 0.9504\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 3s 478us/step - loss: 0.1060 - accuracy: 0.9504\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 3s 480us/step - loss: 0.1030 - accuracy: 0.9515\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 3s 476us/step - loss: 0.1015 - accuracy: 0.9528\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 3s 477us/step - loss: 0.0993 - accuracy: 0.9547\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 3s 475us/step - loss: 0.0983 - accuracy: 0.95490s - loss: 0.0992 - accu\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 3s 481us/step - loss: 0.0972 - accuracy: 0.9542\n",
      "44/44 [==============================] - 0s 501us/step - loss: 0.0992 - accuracy: 0.9560\n",
      "Test Accuracy: 0.9559566974639893\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 3s 479us/step - loss: 0.1804 - accuracy: 0.9247\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1255 - accuracy: 0.9439\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1155 - accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.1107 - accuracy: 0.9484\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 472us/step - loss: 0.1056 - accuracy: 0.9510\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.1031 - accuracy: 0.9534\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1005 - accuracy: 0.9534\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0993 - accuracy: 0.9550\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 474us/step - loss: 0.0970 - accuracy: 0.9541\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.0960 - accuracy: 0.9557\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.0970 - accuracy: 0.9588\n",
      "Test Accuracy: 0.958844780921936\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1847 - accuracy: 0.9234\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1237 - accuracy: 0.9447\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1131 - accuracy: 0.9487\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1080 - accuracy: 0.9507\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 474us/step - loss: 0.1047 - accuracy: 0.9520\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1025 - accuracy: 0.9518\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 3s 478us/step - loss: 0.1014 - accuracy: 0.9517\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0988 - accuracy: 0.9541\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.0980 - accuracy: 0.9533\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.0956 - accuracy: 0.9555\n",
      "44/44 [==============================] - 0s 454us/step - loss: 0.1136 - accuracy: 0.9523\n",
      "Test Accuracy: 0.9523465633392334\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.1819 - accuracy: 0.9251\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 471us/step - loss: 0.1241 - accuracy: 0.9439\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1148 - accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1094 - accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1065 - accuracy: 0.9510\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1042 - accuracy: 0.9505\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.1017 - accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.1003 - accuracy: 0.9539\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0986 - accuracy: 0.9540\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0961 - accuracy: 0.9569\n",
      "44/44 [==============================] - 0s 454us/step - loss: 0.0975 - accuracy: 0.9531\n",
      "Test Accuracy: 0.9530686140060425\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.1814 - accuracy: 0.9254\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 454us/step - loss: 0.1236 - accuracy: 0.9443\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 456us/step - loss: 0.1142 - accuracy: 0.9457\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1089 - accuracy: 0.9499\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1053 - accuracy: 0.9523\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1023 - accuracy: 0.9527\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1007 - accuracy: 0.9540\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.0987 - accuracy: 0.9555\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.0967 - accuracy: 0.9555\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.0964 - accuracy: 0.9548\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.1013 - accuracy: 0.9495\n",
      "Test Accuracy: 0.9494584798812866\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.1813 - accuracy: 0.9253\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.1251 - accuracy: 0.9431\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.1146 - accuracy: 0.9490\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 454us/step - loss: 0.1103 - accuracy: 0.9490\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 471us/step - loss: 0.1068 - accuracy: 0.9504\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1038 - accuracy: 0.9524\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1018 - accuracy: 0.9527\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0997 - accuracy: 0.9532\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.0988 - accuracy: 0.9549\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 456us/step - loss: 0.0971 - accuracy: 0.9550\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.0957 - accuracy: 0.9567\n",
      "Test Accuracy: 0.9566786885261536\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1784 - accuracy: 0.9247\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1234 - accuracy: 0.94470s - loss:\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.1145 - accuracy: 0.9478\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1085 - accuracy: 0.9509\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1052 - accuracy: 0.9517\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1028 - accuracy: 0.9527\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.1011 - accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 461us/step - loss: 0.0986 - accuracy: 0.9534\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.0963 - accuracy: 0.9564\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0961 - accuracy: 0.9554\n",
      "44/44 [==============================] - 0s 431us/step - loss: 0.1175 - accuracy: 0.9487\n",
      "Test Accuracy: 0.9487364888191223\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1740 - accuracy: 0.9264\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1237 - accuracy: 0.9440\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1134 - accuracy: 0.9483\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1091 - accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1062 - accuracy: 0.9528\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1035 - accuracy: 0.9517\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.1016 - accuracy: 0.9525\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0994 - accuracy: 0.9545\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0976 - accuracy: 0.9548\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0974 - accuracy: 0.9553\n",
      "44/44 [==============================] - 0s 454us/step - loss: 0.1008 - accuracy: 0.9495\n",
      "Test Accuracy: 0.9494584798812866\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 474us/step - loss: 0.1803 - accuracy: 0.9246\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1265 - accuracy: 0.9428\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1159 - accuracy: 0.9449\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 473us/step - loss: 0.1101 - accuracy: 0.9514\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1056 - accuracy: 0.9509\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 461us/step - loss: 0.1036 - accuracy: 0.9514\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1006 - accuracy: 0.9540\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 471us/step - loss: 0.0997 - accuracy: 0.9537\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.0979 - accuracy: 0.9559\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.0963 - accuracy: 0.9554\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.1079 - accuracy: 0.9531\n",
      "Test Accuracy: 0.9530686140060425\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 472us/step - loss: 0.1793 - accuracy: 0.9245\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1226 - accuracy: 0.9441\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1136 - accuracy: 0.9484\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1092 - accuracy: 0.9495\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1054 - accuracy: 0.9516\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1036 - accuracy: 0.9510\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 3s 476us/step - loss: 0.1007 - accuracy: 0.9530\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0990 - accuracy: 0.95550s - loss: 0.0987 - accuracy: 0.95\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.0966 - accuracy: 0.9545\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.0961 - accuracy: 0.9553\n",
      "44/44 [==============================] - 0s 454us/step - loss: 0.0983 - accuracy: 0.9588\n",
      "Test Accuracy: 0.958844780921936\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1774 - accuracy: 0.9270\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1239 - accuracy: 0.9431\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1144 - accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1093 - accuracy: 0.9496\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 3s 475us/step - loss: 0.1065 - accuracy: 0.95130s - l\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1040 - accuracy: 0.9495\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1017 - accuracy: 0.9523\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.0991 - accuracy: 0.9543\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.0979 - accuracy: 0.9550\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0961 - accuracy: 0.9552\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.1002 - accuracy: 0.9516\n",
      "Test Accuracy: 0.9516245722770691\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 461us/step - loss: 0.1791 - accuracy: 0.9251\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1245 - accuracy: 0.9453\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1152 - accuracy: 0.94720s - loss: 0.1155 - accuracy\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1110 - accuracy: 0.9488\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1065 - accuracy: 0.9502\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1041 - accuracy: 0.9520\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 470us/step - loss: 0.1023 - accuracy: 0.9523\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.0997 - accuracy: 0.9535\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0985 - accuracy: 0.9542\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.0971 - accuracy: 0.9548\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.0956 - accuracy: 0.9596\n",
      "Test Accuracy: 0.9595667719841003\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.1828 - accuracy: 0.9243\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 455us/step - loss: 0.1250 - accuracy: 0.9434\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.1158 - accuracy: 0.9461\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 457us/step - loss: 0.1103 - accuracy: 0.9500\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1072 - accuracy: 0.9502\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 455us/step - loss: 0.1043 - accuracy: 0.9504\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 461us/step - loss: 0.1022 - accuracy: 0.9534\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 457us/step - loss: 0.0998 - accuracy: 0.9530\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 474us/step - loss: 0.0984 - accuracy: 0.9543\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.0971 - accuracy: 0.9539\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.0900 - accuracy: 0.9545\n",
      "Test Accuracy: 0.9545126557350159\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1828 - accuracy: 0.9220\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 457us/step - loss: 0.1241 - accuracy: 0.9453\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1146 - accuracy: 0.9469\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1087 - accuracy: 0.9497\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.1054 - accuracy: 0.9525\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 469us/step - loss: 0.1023 - accuracy: 0.9516\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.1003 - accuracy: 0.9536\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.0991 - accuracy: 0.9539\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.0963 - accuracy: 0.9559\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.0957 - accuracy: 0.9557\n",
      "44/44 [==============================] - 0s 454us/step - loss: 0.1347 - accuracy: 0.9458\n",
      "Test Accuracy: 0.9458483457565308\n",
      "Epoch 1/10\n",
      "   1/5263 [..............................] - ETA: 0s - loss: 1.5187 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1850 - accuracy: 0.9230\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1243 - accuracy: 0.9434\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1146 - accuracy: 0.9472\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 452us/step - loss: 0.1095 - accuracy: 0.9490\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 456us/step - loss: 0.1056 - accuracy: 0.9512\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 454us/step - loss: 0.1033 - accuracy: 0.9539\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1009 - accuracy: 0.9524\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 461us/step - loss: 0.0989 - accuracy: 0.9548\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.0977 - accuracy: 0.9547\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 461us/step - loss: 0.0961 - accuracy: 0.9557\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.0938 - accuracy: 0.9552\n",
      "Test Accuracy: 0.9552346467971802\n",
      "Epoch 1/10\n",
      "   1/5263 [..............................] - ETA: 0s - loss: 1.3777 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.1816 - accuracy: 0.9238\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 471us/step - loss: 0.1238 - accuracy: 0.9432\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 456us/step - loss: 0.1144 - accuracy: 0.9478\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.1090 - accuracy: 0.9498\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 465us/step - loss: 0.1049 - accuracy: 0.9516\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 473us/step - loss: 0.1022 - accuracy: 0.9536\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.0998 - accuracy: 0.9542\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 462us/step - loss: 0.0986 - accuracy: 0.9539\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.0965 - accuracy: 0.95560s - loss: 0.0974 - accu\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 457us/step - loss: 0.0953 - accuracy: 0.95640s - l\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.1074 - accuracy: 0.9545\n",
      "Test Accuracy: 0.9545126557350159\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.1783 - accuracy: 0.9248\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1244 - accuracy: 0.9428\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1146 - accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.1088 - accuracy: 0.9511\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 457us/step - loss: 0.1051 - accuracy: 0.9526\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 457us/step - loss: 0.1024 - accuracy: 0.9523\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.1005 - accuracy: 0.9539\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.0985 - accuracy: 0.9557\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 459us/step - loss: 0.0969 - accuracy: 0.9544\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.0955 - accuracy: 0.9561\n",
      "44/44 [==============================] - 0s 455us/step - loss: 0.1244 - accuracy: 0.9422\n",
      "Test Accuracy: 0.9421965479850769\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 460us/step - loss: 0.1815 - accuracy: 0.9239\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.1245 - accuracy: 0.9445\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1152 - accuracy: 0.9474\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 3s 476us/step - loss: 0.1089 - accuracy: 0.9503\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 3s 485us/step - loss: 0.1056 - accuracy: 0.9519\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 473us/step - loss: 0.1036 - accuracy: 0.9517\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 3s 483us/step - loss: 0.1002 - accuracy: 0.95430s - loss: 0.0997 - \n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 3s 476us/step - loss: 0.0985 - accuracy: 0.9544\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 3s 496us/step - loss: 0.0970 - accuracy: 0.9546\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 3s 479us/step - loss: 0.0957 - accuracy: 0.9544\n",
      "44/44 [==============================] - 0s 477us/step - loss: 0.0960 - accuracy: 0.9501\n",
      "Test Accuracy: 0.9501445293426514\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 472us/step - loss: 0.1869 - accuracy: 0.9215\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 3s 490us/step - loss: 0.1246 - accuracy: 0.9441\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 471us/step - loss: 0.1155 - accuracy: 0.9475\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 3s 482us/step - loss: 0.1105 - accuracy: 0.9496\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1068 - accuracy: 0.9506\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 3s 481us/step - loss: 0.1047 - accuracy: 0.9509\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 3s 484us/step - loss: 0.1022 - accuracy: 0.9534\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 458us/step - loss: 0.1001 - accuracy: 0.9539\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.0987 - accuracy: 0.9534\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 3s 478us/step - loss: 0.0970 - accuracy: 0.9557\n",
      "44/44 [==============================] - 0s 477us/step - loss: 0.0935 - accuracy: 0.9501\n",
      "Test Accuracy: 0.9501445293426514\n",
      "Epoch 1/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.1762 - accuracy: 0.9263\n",
      "Epoch 2/10\n",
      "5263/5263 [==============================] - 3s 476us/step - loss: 0.1249 - accuracy: 0.9417\n",
      "Epoch 3/10\n",
      "5263/5263 [==============================] - 2s 471us/step - loss: 0.1151 - accuracy: 0.9477\n",
      "Epoch 4/10\n",
      "5263/5263 [==============================] - 3s 479us/step - loss: 0.1103 - accuracy: 0.9485\n",
      "Epoch 5/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1066 - accuracy: 0.9497\n",
      "Epoch 6/10\n",
      "5263/5263 [==============================] - 2s 468us/step - loss: 0.1039 - accuracy: 0.9517\n",
      "Epoch 7/10\n",
      "5263/5263 [==============================] - 2s 463us/step - loss: 0.1010 - accuracy: 0.9543\n",
      "Epoch 8/10\n",
      "5263/5263 [==============================] - 2s 466us/step - loss: 0.0998 - accuracy: 0.9528\n",
      "Epoch 9/10\n",
      "5263/5263 [==============================] - 2s 464us/step - loss: 0.0977 - accuracy: 0.9548\n",
      "Epoch 10/10\n",
      "5263/5263 [==============================] - 2s 467us/step - loss: 0.0960 - accuracy: 0.9561\n",
      "44/44 [==============================] - 0s 432us/step - loss: 0.1124 - accuracy: 0.9516\n",
      "Test Accuracy: 0.9515895843505859\n"
     ]
    }
   ],
   "source": [
    "# Use Kfold cross validation to avoid overfitting\n",
    "K = [2,4,8,10,20]\n",
    "result = []\n",
    "bestModels = {}\n",
    "for k in K:\n",
    "    kfold = KFold(n_splits=k, shuffle=True)\n",
    "    k_result = []\n",
    "    bestModels[k] = [None,0]\n",
    "    for train_index, test_index in kfold.split(X):\n",
    "        x_train,x_test=X[train_index],X[test_index]\n",
    "        y_train,y_test=Y[train_index],Y[test_index]\n",
    "        model = baseline_model()\n",
    "        model.fit(x_train,y_train,epochs=10,batch_size=5, verbose=1)\n",
    "        test_loss, test_acc = model.evaluate(x_test,y_test)\n",
    "        k_result.append(test_acc)\n",
    "        if test_acc > bestModels[k][1]:\n",
    "            bestModels[k][0] = model\n",
    "            bestModels[k][1] = test_acc\n",
    "        print('Test Accuracy:',test_acc)\n",
    "    result.append(k_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95e43c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jiech\\AppData\\Local\\Temp/ipykernel_25372/3050461184.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  result = np.array([np.array(xi) for xi in result])\n"
     ]
    }
   ],
   "source": [
    "R = np.array([np.array(xi) for xi in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "978eb87c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K= 2 Average accuracy and std: 94.59% (0.42%)\n",
      "K= 4 Average accuracy and std: 95.18% (0.25%)\n",
      "K= 8 Average accuracy and std: 95.05% (0.41%)\n",
      "K= 10 Average accuracy and std: 95.14% (0.27%)\n",
      "K= 20 Average accuracy and std: 95.26% (0.43%)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(K)):\n",
    "    print(\"K=\",K[i],\"Average accuracy and std: %.2f%% (%.2f%%)\" % (result[i].mean()*100, result[i].std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cee13211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "260/260 [==============================] - 0s 677us/step - loss: 0.0996 - accuracy: 0.9546\n",
      "K= 2 Accuracy(Test): 95.46%\n",
      "260/260 [==============================] - 0s 665us/step - loss: 0.0964 - accuracy: 0.9570\n",
      "K= 4 Accuracy(Test): 95.70%\n",
      "260/260 [==============================] - 0s 642us/step - loss: 0.0919 - accuracy: 0.9576\n",
      "K= 8 Accuracy(Test): 95.76%\n",
      "260/260 [==============================] - 0s 677us/step - loss: 0.0916 - accuracy: 0.9579\n",
      "K= 10 Accuracy(Test): 95.79%\n",
      "260/260 [==============================] - 0s 638us/step - loss: 0.0925 - accuracy: 0.9585\n",
      "K= 20 Accuracy(Test): 95.85%\n"
     ]
    }
   ],
   "source": [
    "for k in K:\n",
    "    test_loss, test_acc = bestModels[k][0].evaluate(XTest,YTest)\n",
    "    print(\"K=\",k,\"Accuracy(Test): %.2f%%\" % (test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a0c11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
